# UWSS â€“ Universal Web Scraping System

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![GitHub Repo](https://img.shields.io/badge/GitHub-Repository-black.svg)](https://github.com/duynguyenxc/Universal-Web-Scraping-System-high-level-update)

> **UWSS** is an intelligent academic data collection system that can connect to multiple scientific document sources by simply changing configuration.

## ğŸš€ The Problem UWSS Solves

You're conducting research on a scientific topic and need to collect:
- âœ… Papers from arXiv, PubMed
- âœ… Documents from Crossref, Semantic Scholar
- âœ… Data from OpenAlex and other sources

**UWSS helps you:**
- Automatically collect metadata (title, abstract, authors, DOI)
- Download PDF files of papers
- Filter data by relevant keywords
- Export data in multiple formats (JSON, CSV)
- Manage and analyze data quality

## âœ¨ Key Features

### ğŸ” Intelligent Collection
- **Multiple Sources**: arXiv, PubMed, Crossref, Semantic Scholar, OpenAlex
- **Official APIs**: Uses official APIs from each source, compliant with regulations
- **Auto Classification**: Filters relevant papers based on keywords

### ğŸ“Š Data Management
- **Professional Database**: SQLite (local) or PostgreSQL (production)
- **Complete Metadata**: Title, abstract, authors, DOI, publication year
- **Automatic PDFs**: Download and store PDF files

### ğŸ› ï¸ Easy to Use
- **Simple Configuration**: Just edit config.yaml file
- **Command Line Interface**: Intuitive command-line interface
- **Support Scripts**: Tools for analysis and data checking

## ğŸ—ï¸ How UWSS Works

### 5-Step Process

```
1ï¸âƒ£ DISCOVER ğŸ“š â†’ 2ï¸âƒ£ SCORE ğŸ¯ â†’ 3ï¸âƒ£ EXPORT ğŸ“„ â†’ 4ï¸âƒ£ FETCH PDF ğŸ“ â†’ 5ï¸âƒ£ EXTRACT TEXT ğŸ“–
```

**Explanation of each step:**

1. **ğŸ” Discover**: Search for papers from sources (arXiv, PubMed, etc.)
2. **ğŸ¯ Score**: Filter relevant papers using keywords
3. **ğŸ“„ Export**: Save metadata to JSON/CSV files
4. **ğŸ“ Fetch PDF**: Download paper PDF files
5. **ğŸ“– Extract**: Get text content from PDFs

### Supported Data Sources

| Source | Type | Sample Papers |
|--------|------|---------------|
| **arXiv** | Preprints | 269 papers |
| **PubMed** | Medical | Integrated |
| **Crossref** | Multi-disciplinary | 268 papers |
| **Semantic Scholar** | AI Research | 283 papers |
| **OpenAlex** | Open Data | Integrated |

### Collected Data

Each paper includes:
- ğŸ“ **Title** and **abstract**
- ğŸ‘¥ **Authors** and **affiliations**
- ğŸ·ï¸ **Keywords** and **DOI**
- ğŸ“… **Publication year**
- ğŸ”— **PDF link** (if available)

## ğŸš€ Getting Started

### 1. Installation

```bash
# Clone repository
git clone https://github.com/duynguyenxc/Universal-Web-Scraping-System-high-level-update.git
cd Universal-Web-Scraping-System-high-level-update

# Create virtual environment
python -m venv uwss-env
uwss-env\Scripts\activate  # Windows
# source uwss-env/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration

Edit `config/config.yaml`:

```yaml
# Search keywords
domain_keywords:
  - "concrete corrosion"
  - "steel reinforcement"
  - "chloride attack"

# Exclude keywords
negative_keywords:
  - "quantum physics"
  - "machine learning"

# Contact email (for APIs)
contact_email: "your.email@university.edu"
```

### 3. First Test Run

```bash
# Collect data from arXiv
python -m src.uwss.cli paperscraper-discover --max 10

# Filter relevant data
python -m src.uwss.cli score-keywords --config config/config.yaml

# Export results
python -m src.uwss.cli export --require-match --out results.jsonl
```

## ğŸ“‹ Usage Examples

### Collect papers about "concrete corrosion"

```bash
# 1. Discover from multiple sources
python -m src.uwss.cli paperscraper-discover --max 50
python -m src.uwss.cli crossref-lib-discover --max 50
python -m src.uwss.cli semantic-scholar-lib-discover --max 50

# 2. Score relevance
python -m src.uwss.cli score-keywords --config config/config.yaml

# 3. Export high-quality data
python -m src.uwss.cli export --require-match --min-score 0.5 --out corrosion_papers.jsonl

# 4. Download PDFs
python -m src.uwss.cli fetch-pdfs --ids-file filtered_ids.txt --limit 20
```

### Analyze Results

```bash
# View statistics
python scripts/analysis/show_source_summary.py

# Check data quality
python scripts/analysis/check_paperscraper_data.py

# Visualize results
python scripts/analysis/view_scale_test_results.py
```

## ğŸ“‚ Project Structure

```
uwss/
â”œâ”€â”€ config/          # Keyword configuration and settings
â”œâ”€â”€ data/            # Collected data and downloaded PDFs
â”œâ”€â”€ scripts/         # Support utilities
â”‚   â”œâ”€â”€ analysis/    # Data analysis tools
â”‚   â”œâ”€â”€ testing/     # System testing scripts
â”‚   â””â”€â”€ utilities/   # Data maintenance tools
â”œâ”€â”€ src/uwss/        # Main system code
â”œâ”€â”€ test/            # Test results (not committed)
â””â”€â”€ docs/            # Documentation guides
```

## ğŸ¯ Why Use UWSS?

**Before UWSS:**
- ğŸ”´ Manual paper search across multiple websites
- ğŸ”´ Copy-paste metadata from each page
- ğŸ”´ Download PDFs individually
- ğŸ”´ Chaotic data management

**After UWSS:**
- âœ… **Fully automated** collection process
- âœ… **Diverse sources** from 5+ reputable platforms
- âœ… **Quality assurance** with intelligent filtering
- âœ… **Easy expansion** for new research topics

## ğŸ†˜ Support & Contributing

### Report Issues
If you encounter errors:
1. Check log files in `data/runs/`
2. Run analysis scripts: `python scripts/analysis/check_*.py`
3. Create GitHub issue with detailed logs

### Add New Data Sources
The system is designed for easy addition of new sources:
1. Create adapter in `src/uwss/sources/`
2. Add CLI command in `src/uwss/cli/commands/`
3. Test and validate data

## ğŸ“ Contact

**Author:** Duy Nguyen
**Email:** [your.email@university.edu]
**GitHub:** https://github.com/duynguyenxc

## ğŸ“„ License

This project uses MIT License. See LICENSE file for details.

---

<div align="center">

**UWSS - When scientific research meets automation technology**

*ğŸš€ Academic data collection has never been this easy!*

</div>
